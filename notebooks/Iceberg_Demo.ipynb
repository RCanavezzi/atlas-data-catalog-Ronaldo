{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Iceberg Demo\n",
    "\n",
    "## Demonstra√ß√£o do Apache Iceberg com Spark\n",
    "\n",
    "Este notebook demonstra como usar Apache Iceberg para:\n",
    "- Criar tabelas Iceberg\n",
    "- Inserir dados\n",
    "- Consultar dados\n",
    "- Versionamento e time travel\n",
    "- Integra√ß√£o com PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar Spark com Iceberg\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IcebergDemo\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog.type\", \"hive\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.iceberg.warehouse\", \"/home/jovyan/iceberg-warehouse\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark com Iceberg configurado!\")\n",
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar tabela Iceberg de exemplo\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS iceberg.northwind_customers (\n",
    "    customer_id STRING,\n",
    "    company_name STRING,\n",
    "    contact_name STRING,\n",
    "    country STRING,\n",
    "    created_at TIMESTAMP\n",
    ") USING ICEBERG\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Tabela Iceberg criada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar ao PostgreSQL e extrair dados\n",
    "postgres_df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://postgres_erp:5432/northwind\") \\\n",
    "    .option(\"dbtable\", \"customers\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()\n",
    "\n",
    "print(f\"üìä {postgres_df.count()} registros extra√≠dos do PostgreSQL\")\n",
    "postgres_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar e inserir dados no Iceberg\n",
    "from pyspark.sql.functions import current_timestamp, col\n",
    "\n",
    "iceberg_df = postgres_df.select(\n",
    "    col(\"customer_id\"),\n",
    "    col(\"company_name\"),\n",
    "    col(\"contact_name\"),\n",
    "    col(\"country\"),\n",
    "    current_timestamp().alias(\"created_at\")\n",
    ")\n",
    "\n",
    "# Inserir dados na tabela Iceberg\n",
    "iceberg_df.writeTo(\"iceberg.northwind_customers\").append()\n",
    "\n",
    "print(\"‚úÖ Dados inseridos na tabela Iceberg!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar dados do Iceberg\n",
    "result = spark.sql(\"SELECT * FROM iceberg.northwind_customers LIMIT 10\")\n",
    "result.show()\n",
    "\n",
    "# Estat√≠sticas da tabela\n",
    "count = spark.sql(\"SELECT COUNT(*) as total FROM iceberg.northwind_customers\").collect()[0]['total']\n",
    "print(f\"üìä Total de registros na tabela Iceberg: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrar versionamento - inserir mais dados\n",
    "new_data = spark.createDataFrame([\n",
    "    (\"TEST1\", \"Test Company 1\", \"John Doe\", \"Brazil\"),\n",
    "    (\"TEST2\", \"Test Company 2\", \"Jane Smith\", \"Argentina\")\n",
    "], [\"customer_id\", \"company_name\", \"contact_name\", \"country\"])\n",
    "\n",
    "new_data_with_timestamp = new_data.withColumn(\"created_at\", current_timestamp())\n",
    "new_data_with_timestamp.writeTo(\"iceberg.northwind_customers\").append()\n",
    "\n",
    "print(\"‚úÖ Novos dados inseridos!\")\n",
    "\n",
    "# Verificar nova contagem\n",
    "new_count = spark.sql(\"SELECT COUNT(*) as total FROM iceberg.northwind_customers\").collect()[0]['total']\n",
    "print(f\"üìä Nova contagem: {new_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar hist√≥rico da tabela\n",
    "history = spark.sql(\"SELECT * FROM iceberg.northwind_customers.history\")\n",
    "history.show(truncate=False)\n",
    "\n",
    "print(\"üìà Hist√≥rico de vers√µes da tabela Iceberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrar Time Travel (consultar vers√£o anterior)\n",
    "snapshots = spark.sql(\"SELECT * FROM iceberg.northwind_customers.snapshots\")\n",
    "snapshots.show(truncate=False)\n",
    "\n",
    "# Se houver snapshots, consultar o primeiro\n",
    "snapshot_ids = [row['snapshot_id'] for row in snapshots.collect()]\n",
    "if len(snapshot_ids) > 1:\n",
    "    first_snapshot = snapshot_ids[0]\n",
    "    time_travel_query = f\"SELECT COUNT(*) as count_at_snapshot FROM iceberg.northwind_customers VERSION AS OF {first_snapshot}\"\n",
    "    result = spark.sql(time_travel_query)\n",
    "    result.show()\n",
    "    print(f\"üïê Time Travel: Dados no primeiro snapshot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise por pa√≠s\n",
    "country_analysis = spark.sql(\"\"\"\n",
    "SELECT country, COUNT(*) as customer_count\n",
    "FROM iceberg.northwind_customers\n",
    "GROUP BY country\n",
    "ORDER BY customer_count DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "country_analysis.show()\n",
    "print(\"üåç An√°lise de clientes por pa√≠s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informa√ß√µes sobre arquivos da tabela\n",
    "files_info = spark.sql(\"SELECT * FROM iceberg.northwind_customers.files\")\n",
    "files_info.show(truncate=False)\n",
    "\n",
    "print(\"üìÅ Informa√ß√µes sobre arquivos da tabela Iceberg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√£o\n",
    "\n",
    "Este notebook demonstrou:\n",
    "\n",
    "- ‚úÖ **Configura√ß√£o do Iceberg** com Spark\n",
    "- ‚úÖ **Cria√ß√£o de tabelas** Iceberg\n",
    "- ‚úÖ **Integra√ß√£o com PostgreSQL** para extra√ß√£o de dados\n",
    "- ‚úÖ **Inser√ß√£o de dados** em formato Iceberg\n",
    "- ‚úÖ **Versionamento** autom√°tico de dados\n",
    "- ‚úÖ **Time Travel** para consultas hist√≥ricas\n",
    "- ‚úÖ **An√°lise de dados** com SQL\n",
    "- ‚úÖ **Metadados** da tabela e arquivos\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "- Integrar com Apache Atlas para cataloga√ß√£o\n",
    "- Implementar pipelines ETL automatizados\n",
    "- Configurar particionamento para performance\n",
    "- Adicionar compacta√ß√£o autom√°tica"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}