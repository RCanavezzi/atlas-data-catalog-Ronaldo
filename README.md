# Apache Atlas DataOps Lab

> **Laborat√≥rio completo para aprendizado de cataloga√ß√£o de dados com Apache Atlas, PostgreSQL e Python**

## Sobre o Projeto

Este reposit√≥rio fornece um ambiente completo de aprendizado para **Data Governance** e **DataOps** usando Apache Atlas como cat√°logo de dados. O projeto demonstra desde conceitos b√°sicos at√© implementa√ß√µes avan√ßadas de descoberta autom√°tica de metadados, linhagem de dados e integra√ß√£o com bancos relacionais.

### Objetivos de Aprendizado

- **Cataloga√ß√£o de Dados**: Criar e gerenciar cat√°logos de metadados
- **API Integration**: Integrar sistemas via REST APIs do Apache Atlas
- **Data Lineage**: Mapear origem e transforma√ß√µes de dados
- **Metadata Management**: Extrair e organizar metadados estruturais
- **DataOps Practices**: Automatizar descoberta e cataloga√ß√£o

## Arquitetura do Sistema

### Stack Tecnol√≥gica

| Componente | Tecnologia | Vers√£o | Porta | Fun√ß√£o |
|------------|------------|--------|-------|--------|
| **Cat√°logo** | Apache Atlas | 2.3.0 | 21000 | Governan√ßa e metadados |
| **Database** | PostgreSQL | 14.19 | 2001 | Dados de exemplo (Northwind) |
| **Orquestra√ß√£o** | Apache Airflow | 3.0.0 | 5000 | Workflows e ETL |
| **Analytics** | PySpark + Jupyter | Latest | 8888 | An√°lise e notebooks |
| **Data Lake** | Apache Iceberg | 1.4.3 | - | Armazenamento com versionamento |
| **Storage** | HBase (embedded) | - | - | Persist√™ncia Atlas |
| **Search** | Apache Solr (embedded) | - | - | Indexa√ß√£o e busca |
| **Messaging** | Apache Kafka (embedded) | - | - | Eventos e notifica√ß√µes |

## üìÅ Estrutura do Reposit√≥rio

```
atlas-dataops-lab/
‚îú‚îÄ‚îÄ docker-compose.yml          # Orquestra√ß√£o dos servi√ßos
‚îú‚îÄ‚îÄ Dockerfile                  # Atlas customizado
‚îú‚îÄ‚îÄ Dockerfile_Spark           # PySpark + Jupyter + Iceberg
‚îú‚îÄ‚îÄ Dockerfile_AirFlow         # Apache Airflow
‚îú‚îÄ‚îÄ wait-for-atlas.sh          # Script de inicializa√ß√£o
‚îú‚îÄ‚îÄ users-credentials.properties # Autentica√ß√£o Atlas
‚îú‚îÄ‚îÄ requirements.txt           # Depend√™ncias globais
‚îú‚îÄ‚îÄ airflow_connections.py     # Configura√ß√£o de conex√µes
‚îú‚îÄ‚îÄ spark_remote_submit.py     # Wrapper Spark remoto
‚îú‚îÄ‚îÄ .env                       # Vari√°veis de ambiente
‚îú‚îÄ‚îÄ LICENSE                    # Licen√ßa do projeto
‚îú‚îÄ‚îÄ README.md                  # Este arquivo
‚îú‚îÄ‚îÄ .gitignore                # Arquivos ignorados
‚îÇ
‚îú‚îÄ‚îÄ dags/                      # DAGs do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ catalog_postgres_to_atlas.py # DAG de cataloga√ß√£o PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ cleanup_atlas.py       # DAG de limpeza do Atlas
‚îÇ   ‚îú‚îÄ‚îÄ etl_northwind_to_iceberg.py # DAG ETL Spark + Iceberg
‚îÇ   ‚îî‚îÄ‚îÄ setup_spark_connection.py # DAG setup conex√£o Spark
‚îÇ
‚îú‚îÄ‚îÄ spark_jobs/                # Jobs Spark
‚îÇ   ‚îî‚îÄ‚îÄ northwind_to_iceberg.py # ETL Northwind -> Iceberg
‚îÇ
‚îú‚îÄ‚îÄ logs/                      # Logs do Airflow
‚îÇ   ‚îú‚îÄ‚îÄ dag_processor/         # Logs de processamento
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep              # Mant√©m diret√≥rio no Git
‚îÇ
‚îú‚îÄ‚îÄ plugins/                   # Plugins customizados do Airflow
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ data/                      # Datasets para an√°lise
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îî‚îÄ‚îÄ northwind.sql          # Schema e dados PostgreSQL
‚îÇ
‚îú‚îÄ‚îÄ Exercicios/
‚îÇ   ‚îî‚îÄ‚îÄ EXERCICIO_ATLAS.md     # Exerc√≠cio pr√°tico completo
‚îÇ
‚îú‚îÄ‚îÄ lab/
‚îÇ   ‚îú‚îÄ‚îÄ atlas_client.py        # Cliente Python para Atlas API
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configura√ß√µes do laborat√≥rio
‚îÇ   ‚îú‚îÄ‚îÄ data_discovery.py      # Descoberta de dados
‚îÇ   ‚îú‚îÄ‚îÄ lineage_demo.py        # Demonstra√ß√£o de linhagem
‚îÇ   ‚îú‚îÄ‚îÄ postgres_integration.py # Integra√ß√£o PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ LAB_ATLAS_PYTHON.md    # Guia do laborat√≥rio Python
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
‚îÇ   ‚îî‚îÄ‚îÄ run_lab.sh            # Script de execu√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ Lab_Catalogo_Postgres_no_Atlas.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ Iceberg_Demo.ipynb     # Demo Apache Iceberg
‚îÇ   ‚îî‚îÄ‚îÄ data/                  # Dados para notebooks
‚îÇ
‚îî‚îÄ‚îÄ respostas/
    ‚îú‚îÄ‚îÄ config_exercicio.py    # Configura√ß√µes do exerc√≠cio
    ‚îú‚îÄ‚îÄ requirements_exercicio.txt # Depend√™ncias do exerc√≠cio
    ‚îî‚îÄ‚îÄ SOLUCAO_EXERCICIO.py   # Solu√ß√£o completa
```

## In√≠cio R√°pido

### 1. Pr√©-requisitos

- **Docker** >= 20.10
- **Docker Compose** >= 2.0
- **Python** >= 3.8 (opcional, para desenvolvimento local)
- **8GB RAM** dispon√≠vel (recomendado)

### 2. Inicializa√ß√£o

```bash
# Clonar o reposit√≥rio
git clone https://github.com/AleTavares/atlas-dataops-lab.git
cd atlas-dataops-lab

# Iniciar todos os servi√ßos
docker-compose up --build -d

# Aguardar inicializa√ß√£o (5-10 minutos)
./wait-for-atlas.sh

# Verificar status dos servi√ßos
docker-compose ps
```

### 3. Acesso aos Servi√ßos

| Servi√ßo | URL | Credenciais |
|---------|-----|-------------|
| **Apache Atlas** | http://localhost:21000 | admin / admin |
| **Apache Airflow** | http://localhost:5000 | admin / admin |
| **Jupyter Notebook** | http://localhost:8888 | Token: tavares1234 |
| **PostgreSQL** | localhost:2001 | postgres / postgres |

## Laborat√≥rios Dispon√≠veis

### Lab 1: Cliente Atlas B√°sico
```bash
cd lab
pip install -r requirements.txt
python atlas_client.py
```
**Aprenda**: Conex√£o com Atlas, busca de entidades, API REST

### Lab 2: Jupyter Notebook Interativo
```bash
# Acessar: http://localhost:8888 (token: tavares1234)
# Abrir: Lab_Catalogo_Postgres_no_Atlas.ipynb
```
**Aprenda**: Extra√ß√£o de metadados, cataloga√ß√£o autom√°tica, visualiza√ß√£o

### Lab 3: Airflow - Cataloga√ß√£o Autom√°tica
```bash
# Acessar: http://localhost:5000 (admin/admin)
# Executar DAG: catalog_postgres_to_atlas
```
**Aprenda**: Orquestra√ß√£o de workflows de cataloga√ß√£o

### Lab 3.1: Airflow - Limpeza do Atlas
```bash
# Acessar: http://localhost:5000 (admin/admin)
# Executar DAG: cleanup_atlas (execu√ß√£o manual)
```
**Aprenda**: Manuten√ß√£o e limpeza de metadados

### Lab 4: Spark + Iceberg - ETL Completo
```bash
# Acessar: http://localhost:5000 (admin/admin)
# Executar DAG: etl_northwind_to_iceberg
```
**Aprenda**: ETL com Spark, Iceberg, linhagem e tags de qualidade

### Lab 5: Iceberg Demo Interativo
```bash
# Acessar: http://localhost:8888 (token: tavares1234)
# Abrir: Iceberg_Demo.ipynb
```
**Aprenda**: Apache Iceberg, time travel, versionamento

### Lab 6: Exerc√≠cio Pr√°tico Completo
```bash
# Seguir instru√ß√µes em EXERCICIO_ATLAS.md
```
**Aprenda**: Implementa√ß√£o completa de catalogador de dados

## Configura√ß√µes Detalhadas

### Apache Atlas
- **Modo**: Standalone com componentes embedded
- **Storage**: BerkeleyDB para grafos, HBase para metadados
- **Search**: Apache Solr embedded
- **Messaging**: Kafka embedded para eventos
- **Autentica√ß√£o**: File-based (users-credentials.properties)
- **Mem√≥ria**: 1GB heap, 512MB inicial
- **Persist√™ncia**: Volume Docker `atlas_data`

### PostgreSQL Northwind
- **Database**: northwind (carregado automaticamente)
- **Tabelas**: 14 tabelas relacionais completas
  - `customers`, `products`, `orders`, `order_details`
  - `employees`, `categories`, `suppliers`, `shippers`
  - `territories`, `region`, `employee_territories`
  - `customer_demographics`, `customer_customer_demo`
- **Dados**: ~3000 registros com relacionamentos
- **Persist√™ncia**: Volume Docker `postgres_data`

### PySpark + Jupyter
- **Base Image**: jupyter/pyspark-notebook:latest
- **Packages**: requests, psycopg2-binary, pandas, matplotlib, seaborn
- **Volumes**: notebooks/ e data/ mapeados
- **Spark UI**: http://localhost:4040 (quando jobs est√£o rodando)

## üìã DAGs Dispon√≠veis

### 1. **catalog_postgres_to_atlas**
- **Descri√ß√£o**: Cataloga√ß√£o autom√°tica do PostgreSQL Northwind no Atlas
- **Schedule**: Di√°rio (`@daily`)
- **Tasks**: 
  - `extract_metadata` - Extrai metadados do PostgreSQL
  - `create_database` - Cria database no Atlas
  - `catalog_tables` - Cataloga estrutura das tabelas
  - `catalog_columns` - Cataloga colunas das tabelas
- **Execu√ß√£o**: Autom√°tica ou manual

### 2. **cleanup_atlas**
- **Descri√ß√£o**: Limpeza completa de todas as entidades do Atlas
- **Schedule**: Manual apenas
- **Tasks**:
  - `get_all_entities` - Lista todas as entidades
  - `delete_columns` - Remove todas as colunas
  - `delete_tables` - Remove todas as tabelas
  - `delete_databases` - Remove todos os databases
  - `cleanup_remaining` - Limpa entidades restantes
- **‚ö†Ô∏è ATEN√á√ÉO**: Remove TODAS as entidades do Atlas

### 3. **etl_northwind_to_iceberg**
- **Descri√ß√£o**: ETL completo Northwind PostgreSQL para Iceberg Raw Layer
- **Schedule**: Semanal (`@weekly`)
- **Tasks**:
  - `check_spark_job` - Verifica exist√™ncia do job Spark
  - `submit_spark_job` - Executa job Spark no container pyspark-aula
  - `validate_results` - Valida tabelas criadas via Atlas API
- **Funcionalidades**: Extra√ß√£o, cataloga√ß√£o, linhagem, tags de qualidade

### 4. **setup_spark_connection**
- **Descri√ß√£o**: Configura√ß√£o da conex√£o Spark no Airflow
- **Schedule**: Manual apenas
- **Tasks**:
  - `create_spark_connection` - Cria conex√£o spark_container
- **Uso**: Executar uma vez para configurar ambiente

## Comandos √öteis

### Gerenciamento de Servi√ßos
```bash
# Ver logs espec√≠ficos
docker-compose logs -f atlas
docker-compose logs -f postgres_erp
docker-compose logs -f airflow-standalone

# Reiniciar servi√ßo espec√≠fico
docker-compose restart atlas

# Parar todos os servi√ßos
docker-compose down

# Limpar volumes (CUIDADO: perde dados)
docker-compose down -v

# Rebuild completo
docker-compose up --build --force-recreate
```

### Airflow - Gerenciamento de DAGs
```bash
# Listar DAGs
docker exec -it airflow-standalone airflow dags list

# Executar DAG manualmente
docker exec -it airflow-standalone airflow dags trigger catalog_postgres_to_atlas

# Ver status de execu√ß√£o
docker exec -it airflow-standalone airflow dags state catalog_postgres_to_atlas

# Pausar/Despausar DAG
docker exec -it airflow-standalone airflow dags pause catalog_postgres_to_atlas
docker exec -it airflow-standalone airflow dags unpause catalog_postgres_to_atlas
```

### Diagn√≥stico
```bash
# Testar conectividade Atlas
curl -u admin:admin http://localhost:21000/api/atlas/admin/version

# Testar PostgreSQL
docker exec -it postgres-erp psql -U postgres -d northwind -c "SELECT count(*) FROM customers;"

# Verificar recursos
docker stats
```

## Casos de Uso Educacionais

### 1. **Data Discovery**
- Descoberta autom√°tica de esquemas de banco
- Cataloga√ß√£o de tabelas e colunas
- Busca e navega√ß√£o no cat√°logo

### 2. **Metadata Management**
- Extra√ß√£o de metadados estruturais
- Cria√ß√£o de entidades no Atlas
- Relacionamentos entre entidades

### 3. **Data Lineage**
- Mapeamento de origem dos dados
- Rastreamento de transforma√ß√µes
- Visualiza√ß√£o de fluxos de dados

### 4. **API Integration**
- Uso de REST APIs do Atlas
- Autentica√ß√£o e autoriza√ß√£o
- Opera√ß√µes CRUD em metadados

### 5. **DataOps Automation**
- Scripts de cataloga√ß√£o autom√°tica
- Integra√ß√£o com pipelines CI/CD
- Monitoramento de qualidade de dados

## Pr√≥ximos Passos - Roadmap

### Evolu√ß√£o para Plataforma DataOps Completa

Os pr√≥ximos desenvolvimentos deste reposit√≥rio incluir√£o a implementa√ß√£o de uma **plataforma DataOps completa** com orquestra√ß√£o avan√ßada e linhagem autom√°tica de dados:

#### **Apache Airflow - Orquestra√ß√£o de ETLs**
- **Scheduler Avan√ßado**: Orquestra√ß√£o de pipelines de dados complexos
- **DAGs Automatizados**: Workflows para descoberta e cataloga√ß√£o cont√≠nua
- **Monitoramento**: Interface web para acompanhamento de execu√ß√µes
- **Integra√ß√£o Atlas**: DAGs espec√≠ficos para sincroniza√ß√£o de metadados

#### **Apache Spark - Engine de Transforma√ß√£o**
- **Processamento Distribu√≠do**: Transforma√ß√µes em larga escala
- **Conectores Nativos**: Integra√ß√£o direta com PostgreSQL e Atlas
- **Spark Streaming**: Processamento de dados em tempo real
- **Delta Lake**: Versionamento e qualidade de dados

#### **Linhagem Autom√°tica de Dados**
- **Rastreamento Completo**: Origem ‚Üí Transforma√ß√£o ‚Üí Destino
- **Spark Lineage**: Captura autom√°tica via Spark Listener
- **Atlas Integration**: Registro autom√°tico de processos ETL
- **Visualiza√ß√£o Gr√°fica**: Mapeamento visual de fluxos de dados

### **Arquitetura Futura**

### **Funcionalidades Implementadas e Planejadas**

| Componente | Funcionalidade | Status |
|------------|----------------|--------|
| **Airflow** | DAGs de cataloga√ß√£o autom√°tica | ‚úÖ **Implementado** |
| **Airflow** | DAG de limpeza do Atlas | ‚úÖ **Implementado** |
| **Airflow** | DAG ETL Spark + Iceberg | ‚úÖ **Implementado** |
| **Atlas** | Cataloga√ß√£o via API REST | ‚úÖ **Implementado** |
| **Atlas** | Linhagem autom√°tica de dados | ‚úÖ **Implementado** |
| **Atlas** | Tags de qualidade automatizadas | ‚úÖ **Implementado** |
| **PostgreSQL** | Extra√ß√£o de metadados Northwind | ‚úÖ **Implementado** |
| **Spark** | Jobs ETL com Iceberg | ‚úÖ **Implementado** |
| **Iceberg** | Armazenamento com versionamento | ‚úÖ **Implementado** |
| **Monitoring** | Dashboard de qualidade de dados | üìã Planejado |
| **Governance** | Pol√≠ticas avan√ßadas | üìã Planejado |

### **Benef√≠cios da Evolu√ß√£o**

- **Automa√ß√£o Completa**: Descoberta e cataloga√ß√£o sem interven√ß√£o manual
- **Linhagem End-to-End**: Rastreamento completo do ciclo de vida dos dados
- **Escalabilidade**: Processamento distribu√≠do para grandes volumes
- **Governan√ßa Avan√ßada**: Pol√≠ticas e qualidade automatizadas
- **Observabilidade**: Monitoramento completo de pipelines

### **Como Contribuir**

Interessado em contribuir com essas funcionalidades? √Åreas de desenvolvimento:

- **Airflow DAGs**: Desenvolvimento de workflows de cataloga√ß√£o
- **Spark Jobs**: Implementa√ß√£o de ETLs com captura de linhagem
- **Atlas Hooks**: Conectores customizados para diferentes fontes
- **Monitoring**: Dashboards e alertas de qualidade
- **Documentation**: Tutoriais e guias avan√ßados

## Contribui√ß√£o

Este √© um projeto educacional. Contribui√ß√µes s√£o bem-vindas:

1. **Fork** o reposit√≥rio
2. **Crie** uma branch para sua feature
3. **Commit** suas mudan√ßas
4. **Push** para a branch
5. **Abra** um Pull Request

### √Åreas de Melhoria Atuais
- Novos conectores de dados
- Exemplos de classifica√ß√£o autom√°tica
- Integra√ß√£o com ferramentas de BI
- Testes automatizados
- Documenta√ß√£o adicional

## Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para detalhes.

## Agradecimentos

- **Apache Atlas Community** - Pela excelente ferramenta de governan√ßa
- **Northwind Database** - Pelo dataset educacional cl√°ssico
- **Docker Community** - Pela containeriza√ß√£o simplificada
- **Jupyter Project** - Pelo ambiente interativo de an√°lise

**üìö Para come√ßar, acesse os laborat√≥rios em ordem:**
1. [Lab Python B√°sico](lab/LAB_ATLAS_PYTHON.md)
2. [Exerc√≠cio Pr√°tico](Exercicios/EXERCICIO_ATLAS.md)
3. [Notebook Interativo](notebooks/Lab_Catalogo_Postgres_no_Atlas.ipynb)